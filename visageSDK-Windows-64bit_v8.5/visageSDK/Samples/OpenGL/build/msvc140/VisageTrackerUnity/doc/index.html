<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>VisageTrackerUnity: visage|SDK VisageTrackerUnity example project</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">VisageTrackerUnity
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">visage|SDK VisageTrackerUnity example project </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p> 
<table border="0">
<tr>
<td width="32"><a href="../../../../../../bin64/VisageTrackerUnityDemo.exe"><img src="../../../../../../doc/OpenGL/images/run_sample.png" border=0 title="Run Sample (this may not work in all browsers, in such case please run VisageTrackerUnityDemo.exe from the visageSDK\bin64 folder.)"></a></td>
<td width="32"><a href="../../../../../../bin64"><img src="../../../../../../doc/OpenGL/images/open_bin_folder.png" border=0 title="Open Binary Folder (visageSDK\bin64)"></a></td>
<td width="32"><a href="../../../../data/VisageTrackerUnity"><img src="../../../../../../doc/OpenGL/images/open_data_folder.png" border=0 title="Open Data Folder"></a></td>
<td width="32"><a href="../../../../data/Videos"><img src="../../../../../../doc/OpenGL/images/open_folder.png" border=0 title="Open Video Folder"></a></td>
<td width="32"><a href="../../../../build/msvc140/VisageTrackerUnity"><img src="../../../../../../doc/OpenGL/images/open_project_folder.png" border=0 title="Open Project Folder"></a></td>
<td width="32"><a href="../../../../source/VisageTrackerUnity"><img src="../../../../../../doc/OpenGL/images/open_source_folder.png" border=0 title="Open Source Code Folder"></a></td>
</tr>
</table>
</p>
<p>The VisageTrackerUnity sample project demonstrates the integration of visage|SDK with Unity game engine and is aimed at developers starting to use face tracking, face analysis and face recognition functionalities of visage|SDK in Unity game engine and development tool.</p>
<p>The sample project shows how face tracking is used to put a virtual object (glasses) on the user's face in Unity, and how to access the full 3D face model of the face. Sample also demonstrates how to use face tracking results to obtain face analysis and face recognition results. Developers may use parts of this project to speed up their own development in Unity using visage|SDK or use this application as a starting point for own projects.</p>
<h1><a class="anchor" id="using"></a>
Using the sample applications</h1>
<p><br />
<br />
 In order to try the sample application, you need to have a valid license key. More information on how to obtain license key and include it in the application can be found in <a href="../../../../../../doc/OpenGL/licensing.html"><em>Licensing</em></a> section of the documentation. <br />
<br />
 To start the application, double-click on VisageTrackerUnity.exe located in <em>visageSDK/bin64 </em>folder.</p>
<p>Tracking will start automatically when a face is found in the camera frame. Available buttons are:</p><ul>
<li>Play/Pause in the lower left corner (resumes/pauses tracking).</li>
<li>Switch camera in the lower right corner.</li>
<li>Switch effect in the upper right corner of the screen (switches between rendering glasses or a tiger texture)</li>
<li>Enable face recognition in upper left corner of the screen</li>
</ul>
<p>On top of the video frames is a 3D model of glasses or tiger model (depending on which effect is chosen) that is transformed with the information about rotation and translation from the tracker. It blends seamlessly with the background video.</p>
<h1><a class="anchor" id="building"></a>
Building the project</h1>
<p>The files related to VisageTrackerUnity sample project are located in the Samples/OpenGL/data/VisageTrackerUnity subfolder of the visage|SDK folder.</p>
<p>The application was built and tested with version 2018.3.0f2.</p>
<p>To build VisageTrackerUnity sample two steps are involved: creating the Unity project from the provided Unity package and building the application.</p>
<h2><a class="anchor" id="creatingUnity"></a>
Creating the Unity project from Unity package</h2>
<p>To create the Unity project from provided Unity package follow these steps:</p><ol type="1">
<li>Create a new Unity project</li>
<li>Import VisageTrackerUnity.unitypackage (provided in Samples/OpenGL/data/VisageTrackerUnity folder) by selecting Assets-&gt;Import Package-&gt;Custom Package... item from the menu. That way all the assets that are used by the example project will be imported into the new project.</li>
<li>Select and open the Main scene.</li>
</ol>
<h2><a class="anchor" id="generateApp"></a>
Building the application</h2>
<p>To build the application follow these steps:</p><ol type="1">
<li>Build the application by selecting File-&gt;Build settings and under Platform choose PC and Mac Standalone and set Windows as target platform. Check if the correct Architecture is set: <em>x86_64</em>.</li>
<li>Press the Build button to generate the project, a dialog window will appear. In this window, locate and set destination folder to <em>visageSDK/bin64</em>.</li>
</ol>
<h2><a class="anchor" id="editor"></a>
Running the project through Unity editor</h2>
<ol type="1">
<li>Follow steps on creating a Unity project.</li>
<li>Application is dependent on libraries located in <em>visageSDK/bin64 </em>folder. Copy libraries to the Unity project root folder (e.g. <em>C:/MyUnityProjects/VisageTrackerUnity</em>):<ul>
<li>opencv_core2411.dll</li>
<li>opencv_imgproc2411.dll</li>
<li>VisageTrackerUnityPlugin64.dll<ul>
<li>libVisageVision64.dll<ul>
<li>libopenblas.dll<ul>
<li>libgfortran-3.dll</li>
<li>libquadmath-0.dll</li>
<li>libgcc_s_seh-1.dll</li>
</ul>
</li>
</ul>
</li>
<li>libVisageAnalyser64.dll</li>
</ul>
</li>
</ul>
</li>
<li>Create a <a href="https://docs.unity3d.com/Manual/StreamingAssets.html" target="New">StreamingAssets/Visage Tracker</a> folder in your Unity project Assets folder</li>
<li>Copy following files and folders from the <em>visageSDK/Samples/data</em> folder to the <em>StreamingAssets/Visage Tracker</em> folder:<ul>
<li>bdtsdata folder</li>
<li>candide3.wfm</li>
<li>candide3.fdp</li>
<li>jk_300.wfm</li>
<li>jk_300.fdp</li>
<li>configuration file (e.g. Head Tracker.cfg)</li>
</ul>
</li>
</ol>
<p>NOTE: In case you have license key file, add it also to the <em>StreamingAssets/Visage Tracker</em> folder. Additionally, set the <em>licenseString</em> member of the LicenseString class (script LicenseString.cs) so it contains name of the license key file.</p>
<h1><a class="anchor" id="implementation"></a>
Implementation overview</h1>
<p>The project consists of a main scene with the Unityâ€™s GameObjects that provide different functionalities. A GameObject is the main building block of a scene in Unity. It consists of different Components and can parent other GameObjects. Manipulation of GameObjects is done with Scripts. It is recommended for developers to get familiar with Unity basics before continuing. The integration with visage|SDK is done through a plugin (VisageTrackerUnityPlugin) that wraps native code calls to visage|SDK and provides functions that can be called from Unity scripts.</p>
<h2><a class="anchor" id="trackerGO"></a>
Tracker GameObject</h2>
<p>The core of the example is the Tracker GameObject. It consists of different components attached to it. The main component of the Tracker GameObject is the Tracker script component that handles the communication with the tracker (starts it and gets results from it). The behaviour of the script can be modified by changing its properties and the script code. Other properties can be added as well. The existing Tracker script properties of interest are as follows:</p><ul>
<li>Controllable Objects: list of objects that will be transformed automatically while the face tracking is performed</li>
<li>Config File: filename of the configuration file that will be used by the tracker</li>
</ul>
<p><b>Note:</b> Because of the different coordinate systems used by the visage|SDK face tracker and the Unity game engine mirroring around x-axis is applied to the relevant GameObjects.</p>
<p>Objects in the scene that are also in the Controllable Objects list are the Glasses Model GameObjects.</p>
<h2><a class="anchor" id="analyserGO"></a>
Analyser GameObject</h2>
<p>Analyser GameObject is used to obtain and display face analysis results. It relies on the functionality of the Tracker object, i.e. Tracker script component. The GameObject consists of different components attached to it. The main component of the Analyser GameObject is the Analyser script component that handles the communication with the face analyser (initializes it and gets results from it). The behaviour of the script can be modified by changing its properties and the script code. Other properties can be added as well. The existing Analyser script properties of interest are as follows:</p><ul>
<li>Data Path Analysis: path to data files used to initialize face analysis.</li>
<li>Analysis Data Element: prefab attached to the Analyser GameObject which contains the components needed to display information about the person's age, gender and emotions.</li>
<li>Analysis list: list of Analysis Data Elements instances for each tracked face that will be transformed while the face tracking is performed.</li>
</ul>
<h2><a class="anchor" id="recognitionGO"></a>
Recognition GameObject</h2>
<p>Recognition GameObject is used to obtain and display face recognition results. It relies on the functionality of the Tracker object, i.e. Tracker script component. The GameObject consists of different components attached to it. The main component of the Recognition GameObject is the Recognition script component that handles the communication with the face recognition (initializes it and gets results from it). The behaviour of the script can be modified by changing its properties and the script code. Other properties can be added as well. The existing Recognition script properties of interest are as follows:</p><ul>
<li>Data R Folder: path to data files used to initialize face recognition.</li>
<li>Recognition Gallery: UI panel object used to hold all collected indentities.</li>
<li>Identity: prefab attached to the Recognition GameObject which contains text mesh used to display indentity of a particular person that will be transformed while face tracking is performed.</li>
</ul>
<h2><a class="anchor" id="cameras"></a>
Cameras</h2>
<p>There are two cameras in the scene, one for 3D scene (Main Camera) and other for video display (Video Camera). The main camera "Field of View" is automatically set according to the Tracker focus (camera_focus parameter in configuration file) and input image aspect by the Tracker script. The Video Camera renders objects in the Video layer by using orthographic projection.</p>
<h2><a class="anchor" id="videoObject"></a>
Video object</h2>
<p>Video GameObject contains Video Plane that is used for displaying video and is automatically scaled to input frame aspect ratio by the VideoController script attached to it. In this project the material used by the Video Plane is tinted green to differentiate it from the textured 3D face model that uses the same texture.</p>
<h2><a class="anchor" id="glassesObject"></a>
Glasses object</h2>
<p>The rotation and translation information from the tracker are applied to the Glasses object as they are in the Tracker script Controllable Objects list. This enables overlaying virtual objects to the tracked face that transform correctly with it. Other custom objects can be used instead of the glasses object. For the correct size and positioning of the glasses objects and also on how to achieve occlusion refer to the <a href="../../../../../../doc/OpenGL/modeling_guide.pdf">Animation &amp; AR modeling guide</a>.</p>
<h2><a class="anchor" id="plugin"></a>
VisageTrackerUnityPlugin</h2>
<p>The integration of visage|SDK face tracking with Unity is done through a plugin that wraps native code calls and provides functions that can be called from Unity scripts. The provided prebuilt plugin VisageTrackerUnityPlugin.dll can be used as-is. For more information about the plugin including it's source code, see the VisageTrackerUnityPlugin project and its documentation. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Mar 14 2019 14:47:49 for VisageTrackerUnity by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
